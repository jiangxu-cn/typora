# 使用LLaMA Factory微调多模态大模型

[LLaMA Factory](https://github.com/hiyouga/LLaMA-Factory)是一款开源低代码大模型微调框架，集成了业界最广泛使用的微调技术，支持通过Web UI界面零代码微调大模型，目前已经成为开源社区内最受欢迎的微调框架，GitHub星标超过2万。本文基基于通义千问团队开源的新一代多模态大模型 Qwen2-VL-2B-Instruct，完成文旅领域大模型的构建。

## 前置环境准备

安装LLaMA Factory及其依赖环境

```shell
git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip uninstall -y accelerate vllm matplotlib
pip install llamafactory==0.9.0
```

运行如下命令，如果显示llamafactory-cli的版本，则表示安装成功。

```shell
llamafactory-cli version
```

## 下载数据集

LLaMA-Factory项目内置了丰富的数据集，放在了`data`目录下。可以直接使用内置数据集。也可以准备自定义数据集，将数据处理为框架特定的格式，放在`data`下，并且修改`dataset_info.json`文件。

每条样本都由一条系统提示、一条用户指令和一条模型回答组成，微调过程中模型不断学习样本中的回答风格，从而达到学习文旅知识的目的。数据样例如下所示：

```json
[
  {
    "conversations": [
      {
        "from": "system",
        "value": "你是一个导游，请生动有趣地回答游客提出的问题"
      },
      {
        "from": "human",
        "value": "给我讲讲这个东西<image>"
      },
      {
        "from": "gpt",
        "value": "各位游客朋友们，大家好！\n\n现在映入大家眼帘的，是一件极为珍贵的文物——**神面纹玉戚**。它可不是一般的宝贝，而是来自遥远的新石器时代的一件精美玉器哦！\n\n这件宝贝现藏于山西博物院，它的尺寸相当精致：高20.6厘米，宽13.1厘米，厚仅0.4厘米，真是薄如蝉翼，工艺精湛！\n\n1964年，它在黎城县后庄村广志山出土，仿佛穿越时空，向我们诉说着古老的故事。\n\n大家仔细看，这块玉戚采用了线刻工艺，一侧雕刻着神人的半侧面头像，头戴华美的冠饰，披拂着飘逸的长发，眼眉清晰可辨，仿佛在凝视着我们；而另一侧则是一个方形台座上置神人冠饰的形象，显得神秘而威严。\n\n要知道，玉戚在古代可是象征军事统帅权力的神器，握有它，就如同掌握了千军万马！\n\n大家不妨多停留片刻，感受一下这件文物散发出的古老而神秘的气息吧！\n\n谢谢大家的聆听，接下来我们将继续参观其他精彩展品，敬请期待！"
      }
    ],
    "images": [
      "images/instance_1579398113581395972.jpg"
    ]
  }
]
```

## 模型微调

做好前序准备工作后，直接运行下述命令就可以启动 Web UI。这里用到的环境变量解释如下：

- `USE_MODELSCOPE_HUB` 设为 1，表示模型从 ModelScope 魔搭社区下载。避免从 HuggingFace 下载模型导致网速不畅。

点击返回的 URL 地址，进入 Web UI 页面。

```shell
USE_MODELSCOPE_HUB=1 llamafactory-cli webui
```

### 配置参数

进入 WebUI 后，可以切换语言到中文（zh）。首先配置模型，本教程选择 **Qwen2VL-2B-Chat** 模型，微调方法修改为 **full**，针对小模型使用全参微调方法能带来更好的效果。



数据集使用`train.json`。



可以点击「预览数据集」。点击关闭返回训练界面。



设置学习率为1e-4，梯度累积为2，有利于模型拟合。如果显卡是V100，计算类型保持为fp16；如果使用了A10，可以更改计算类型为bf16。





在其他参数设置区域修改保存间隔为 **1000**，节省硬盘空间。



点击LoRA参数设置展开参数列表，设置LoRA+学习率比例为16，LoRA+被证明是比LoRA学习效果更好的算法。在LoRA作用模块中填写all，即将LoRA层挂载到模型的所有线性层上，提高拟合效果。



###  启动微调

将输出目录修改为 `train_qwen2vl`，训练后的模型权重将会保存在此目录中。点击「预览命令」可展示所有已配置的参数，您如果想通过代码运行微调，可以复制这段命令，在命令行运行。

点击「开始」启动模型微调。



启动微调后需要等待一段时间，待模型下载完毕后可在界面观察到训练进度和损失曲线。模型微调大约需要 14 分钟，显示“训练完毕”代表微调成功。



## 模型评估

选择「Evaluate&Predict」栏，在数据集下拉列表中选择「eval」（验证集）评估模型。更改输出目录为`eval_llama3`，模型评估结果将会保存在该目录中。最后点击开始按钮启动模型评估。



模型评估大约需要5分钟左右，评估完成后会在界面上显示验证集的分数。其中ROUGE分数衡量了模型输出答案（predict）和验证集中标准答案（label）的相似度，ROUGE分数越高代表模型学习得更好。



## 模型对话



选择「Chat」栏，将**检查点路径**改为 `train_qwen2vl`，点击「加载模型」即可在 Web UI 中和微调后的模型进行对话。

首先点击下载[测试图片1](https://dsw-js.data.aliyun.com/production/pai-dsw-examples/v0.6.177/deepLearning/nlp/llama_factory_qwen2vl/preview/_html/demo_pic_1.jpg)或[测试图片2](https://dsw-js.data.aliyun.com/production/pai-dsw-examples/v0.6.177/deepLearning/nlp/llama_factory_qwen2vl/preview/_html/demo_pic_2.jpg)，并上传至对话框的**图像**区域，接着在**系统提示词**区域填写“你是一个导游，请生动有趣地回答游客提出的问题”。在页面底部的对话框输入想要和模型对话的内容，点击提交即可发送消息。。



发送后模型会逐字生成回答，从回答中可以发现模型学习到了数据集中的内容，能够恰当地模仿导游的语气介绍图中的山西博物院。



点击「卸载模型」，点击检查点路径输入框**取消勾选**检查点路径，再次点击「加载模型」，即可与微调前的原始模型聊天。



重新向模型发送相同的内容，发现原始模型无法准确识别山西博物院。